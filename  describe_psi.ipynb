{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e895842-1db6-4ed4-a691-f0be2da2ebe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import pickle\n",
    "import joblib\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz\n",
    "\n",
    "from scipy.stats import ks_2samp, variation\n",
    "\n",
    "import string\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3cbca0-a0e0-4cab-ba7b-b4c90ac53f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular estatísticas descritivas para cada variável em diferentes BASES\n",
    "def calculate_statistics(df, variable):\n",
    "    statistics = []\n",
    "    categories = df['BASE'].unique()\n",
    "    for i in range(len(categories) - 1):\n",
    "        current_cat = categories[i]\n",
    "        next_cat = categories[i + 1]\n",
    "        subset_current = df[df['BASE'] == current_cat][variable]\n",
    "        subset_next = df[df['BASE'] == next_cat][variable]\n",
    "        \n",
    "        # Remover valores NaN antes de calcular o PSI\n",
    "        subset_current2 = subset_current.dropna()\n",
    "        subset_next2 = subset_next.dropna()\n",
    "\n",
    "        psi = calculate_psi(subset_current2, subset_next2)\n",
    "\n",
    "        statistics.append({\n",
    "            'Variable': variable,\n",
    "            'Current_Category': current_cat,\n",
    "            'Next_Category': next_cat,\n",
    "            'min': subset_current.min(),\n",
    "            '1st_quartile': subset_current.quantile(0.25),\n",
    "            'mean': subset_current.mean(),\n",
    "            'median': subset_current.median(),\n",
    "            '3rd_quartile': subset_current.quantile(0.75),\n",
    "            'max': subset_current.max(),\n",
    "            'std_dev': subset_current.std(),\n",
    "            'count': subset_current.count(),\n",
    "            'null_count': subset_current.isnull().sum(),\n",
    "            'PSI': psi\n",
    "        })\n",
    "\n",
    "    # Para o último, onde não há próximo, calcular apenas as estatísticas descritivas\n",
    "    last_cat = categories[-1]\n",
    "    subset_last = df[df['BASE'] == last_cat][variable]\n",
    "    statistics.append({\n",
    "        'Variable': variable,\n",
    "        'Current_Category': last_cat,\n",
    "        'Next_Category': np.nan,\n",
    "        'min': subset_last.min(),\n",
    "        '1st_quartile': subset_last.quantile(0.25),\n",
    "        'mean': subset_last.mean(),\n",
    "        'median': subset_last.median(),\n",
    "        '3rd_quartile': subset_last.quantile(0.75),\n",
    "        'max': subset_last.max(),\n",
    "        'std_dev': subset_last.std(),\n",
    "        'count': subset_last.count(),\n",
    "        'null_count': subset_last.isnull().sum(),\n",
    "        'PSI': np.nan  # PSI não calculado para o último\n",
    "    })\n",
    "    return statistics\n",
    "\n",
    "def calculate_psi(current_dist, next_dist, bins=10):\n",
    "    \"\"\"\n",
    "    Calculate the Population Stability Index (PSI) between current and next distributions.\n",
    "    \n",
    "    Parameters:\n",
    "        current_dist (array-like): Distribution of values for the current period.\n",
    "        next_dist (array-like): Distribution of values for the next period.\n",
    "        bins (int): Number of bins to use for calculating distributions.\n",
    "        \n",
    "    Returns:\n",
    "        float: Population Stability Index (PSI) value.\n",
    "    \"\"\"\n",
    "    # Equalize o número de bins entre as distribuições atual e próxima\n",
    "    _, current_bins = np.histogram(current_dist, bins=bins)\n",
    "    _, next_bins = np.histogram(next_dist, bins=current_bins)\n",
    "    \n",
    "    # Calcular as proporções para cada bin em ambas as distribuições\n",
    "    current_props = np.histogram(current_dist, bins=current_bins)[0] / len(current_dist)\n",
    "    next_props = np.histogram(next_dist, bins=next_bins)[0] / len(next_dist)\n",
    "    \n",
    "    # Calcular o PSI para cada bin\n",
    "    psi_values = (next_props - current_props) * np.log(next_props / current_props)\n",
    "    \n",
    "    # Filtrar valores NaN e infinitos\n",
    "    psi_values = psi_values[~np.isnan(psi_values) & ~np.isinf(psi_values)]\n",
    "    \n",
    "    # Calcular o PSI como a soma dos valores de PSI para todos os bins\n",
    "    psi = np.sum(psi_values)\n",
    "    \n",
    "    return psi\n",
    "\n",
    "# Suponha que df_mod_churn seja o nome do seu DataFrame\n",
    "features_number = [lista]\n",
    "\n",
    "all_statistics = []\n",
    "for feature in features_number:\n",
    "    if feature != 'BASE':  # Se a variável não é 'BASE', calcular estatísticas\n",
    "        all_statistics.extend(calculate_statistics(df_mod_1o, feature))\n",
    "\n",
    "# Criar DataFrame com as estatísticas\n",
    "statistics_df = pd.DataFrame(all_statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d1c4a3-54c2-4b42-90fc-3120d199d5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
